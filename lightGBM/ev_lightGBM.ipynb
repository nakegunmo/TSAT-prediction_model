{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a86c3b",
   "metadata": {},
   "source": [
    "## light-GBMによる極値予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b3165",
   "metadata": {},
   "source": [
    "ステップ1：ライブラリと定数の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nagumo/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 定数\n",
    "TRAIN_PATH  = \"/home/nagumo/TSAT/CryptoData/5min_Full/5min_Full_Train/BTC_full_5min_Full_Train.csv\"\n",
    "VALID_PATH  = \"/home/nagumo/TSAT/CryptoData/5min_Full/5min_Full_Valid/BTC_full_5min_Full_Valid.csv\"\n",
    "WINDOW      = 288  # 過去24時間分（5分刻み×288）\n",
    "SEED        = 42\n",
    "\n",
    "# 指定パラメータ（1パターン）\n",
    "PARAMS = {\n",
    "    'num_leaves':    31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators':  200,\n",
    "    'objective':     'multiclass',\n",
    "    'num_class':     3,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose':       -1,\n",
    "    'seed':          SEED,\n",
    "    # class_weight を強化\n",
    "    # 'class_weight':  {0: 10.0, 1: 10.0, 2: 1.0}\n",
    "}\n",
    "\n",
    "# 出力ディレクトリ\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76358716",
   "metadata": {},
   "source": [
    "ステップ2：データ読み込み＆クリーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58779cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(path):\n",
    "    df = pd.read_csv(path, parse_dates=['date'], index_col='date')\n",
    "    # 5分刻みの連続データのみを抽出\n",
    "    return df.asfreq('5T').dropna()\n",
    "\n",
    "df_train = load_and_clean(TRAIN_PATH)\n",
    "df_valid = load_and_clean(VALID_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fc2444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>46211.24</td>\n",
       "      <td>46386.33</td>\n",
       "      <td>46150.00</td>\n",
       "      <td>46306.89</td>\n",
       "      <td>184.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:05:00</th>\n",
       "      <td>46315.10</td>\n",
       "      <td>46504.00</td>\n",
       "      <td>46268.25</td>\n",
       "      <td>46364.90</td>\n",
       "      <td>164.7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:10:00</th>\n",
       "      <td>46363.03</td>\n",
       "      <td>46388.00</td>\n",
       "      <td>46257.90</td>\n",
       "      <td>46316.17</td>\n",
       "      <td>89.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:15:00</th>\n",
       "      <td>46315.45</td>\n",
       "      <td>46339.90</td>\n",
       "      <td>46211.35</td>\n",
       "      <td>46265.41</td>\n",
       "      <td>67.0770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:20:00</th>\n",
       "      <td>46265.42</td>\n",
       "      <td>46400.00</td>\n",
       "      <td>46262.12</td>\n",
       "      <td>46397.00</td>\n",
       "      <td>87.3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:35:00</th>\n",
       "      <td>16529.41</td>\n",
       "      <td>16573.00</td>\n",
       "      <td>16519.90</td>\n",
       "      <td>16535.96</td>\n",
       "      <td>146.5723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:40:00</th>\n",
       "      <td>16534.42</td>\n",
       "      <td>16576.00</td>\n",
       "      <td>16528.00</td>\n",
       "      <td>16536.93</td>\n",
       "      <td>87.8290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:45:00</th>\n",
       "      <td>16536.93</td>\n",
       "      <td>16576.00</td>\n",
       "      <td>16527.70</td>\n",
       "      <td>16528.45</td>\n",
       "      <td>154.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:50:00</th>\n",
       "      <td>16529.92</td>\n",
       "      <td>16568.00</td>\n",
       "      <td>16521.70</td>\n",
       "      <td>16529.01</td>\n",
       "      <td>70.3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:55:00</th>\n",
       "      <td>16530.14</td>\n",
       "      <td>16568.00</td>\n",
       "      <td>16525.00</td>\n",
       "      <td>16528.03</td>\n",
       "      <td>29.4746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105081 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume\n",
       "date                                                                 \n",
       "2022-01-01 00:00:00  46211.24  46386.33  46150.00  46306.89  184.9810\n",
       "2022-01-01 00:05:00  46315.10  46504.00  46268.25  46364.90  164.7490\n",
       "2022-01-01 00:10:00  46363.03  46388.00  46257.90  46316.17   89.0320\n",
       "2022-01-01 00:15:00  46315.45  46339.90  46211.35  46265.41   67.0770\n",
       "2022-01-01 00:20:00  46265.42  46400.00  46262.12  46397.00   87.3910\n",
       "...                       ...       ...       ...       ...       ...\n",
       "2022-12-31 23:35:00  16529.41  16573.00  16519.90  16535.96  146.5723\n",
       "2022-12-31 23:40:00  16534.42  16576.00  16528.00  16536.93   87.8290\n",
       "2022-12-31 23:45:00  16536.93  16576.00  16527.70  16528.45  154.5496\n",
       "2022-12-31 23:50:00  16529.92  16568.00  16521.70  16529.01   70.3992\n",
       "2022-12-31 23:55:00  16530.14  16568.00  16525.00  16528.03   29.4746\n",
       "\n",
       "[105081 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered = df_train[df_train.index >= '2022-01-01']\n",
    "df_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd87b7c6",
   "metadata": {},
   "source": [
    "ステップ3：ラベル生成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33297960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(close_series, k):\n",
    "    w = 2*k + 1\n",
    "    roll_max = close_series.rolling(w, center=True).max()\n",
    "    roll_min = close_series.rolling(w, center=True).min()\n",
    "    labels = pd.Series(2, index=close_series.index)\n",
    "    labels[close_series == roll_max] = 1  # 極大\n",
    "    labels[close_series == roll_min] = 0  # 極小\n",
    "    return labels.iloc[k:-k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dd688",
   "metadata": {},
   "source": [
    "ステップ4：特徴量生成関数（ログリターン＋hl_diff、lag0含む）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ae1dd",
   "metadata": {},
   "source": [
    "予測時点でのcloseでログリターンと高低差を正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "829f888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_ts_features_norm(df, window):\n",
    "#     # （1）ログリターンと高低差比を計算\n",
    "#     log_ret = np.log(df['close'] / df['close'].shift(1))\n",
    "#     hl_diff = (df['high'] - df['low']) / df['close']\n",
    "\n",
    "#     # （2）lag 特徴量をリスト内包で生成\n",
    "#     log_feats = [log_ret.shift(lag).rename(f'log_ret_lag_{lag}') for lag in range(window)]\n",
    "#     hl_feats  = [hl_diff.shift(lag).rename(f'hl_diff_lag_{lag}')   for lag in range(window)]\n",
    "\n",
    "#     # （3）一括結合＆NaN除去\n",
    "#     feat = pd.concat(log_feats + hl_feats, axis=1)\n",
    "#     feat.dropna(inplace=True)\n",
    "#     return feat\n",
    "\n",
    "# # 特徴量作成\n",
    "# # feat_train = make_ts_features_norm(df_train, WINDOW)\n",
    "# feat_train = make_ts_features_norm(df_train_filtered, WINDOW)\n",
    "# feat_valid = make_ts_features_norm(df_valid, WINDOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08c0058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating lag features:   0%|          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating lag features: 100%|██████████| 288/288 [00:00<00:00, 499.94it/s]\n",
      "Generating lag features: 100%|██████████| 288/288 [00:00<00:00, 696.33it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ── ステップ4：特徴量生成関数 ──────────────────────────\n",
    "def make_ts_features_norm(df, window):\n",
    "    \"\"\"\n",
    "    各時刻 t について、過去 window ステップの\n",
    "    - ログリターン(log_ret)\n",
    "    - 高低差比(hl_diff)\n",
    "    を lag 毎に生成し、一括で concat して返す\n",
    "    \"\"\"\n",
    "    log_ret = np.log(df['close'] / df['close'].shift(1))\n",
    "    hl_diff = (df['high'] - df['low']) / df['close']\n",
    "\n",
    "    # lag特徴量リストをプログレスバー付きで構築\n",
    "    log_ret_feats = []\n",
    "    hl_diff_feats = []\n",
    "    for lag in tqdm(range(window), desc=\"Generating lag features\"):\n",
    "        log_ret_feats.append(log_ret.shift(lag).rename(f'log_ret_lag_{lag}'))\n",
    "        hl_diff_feats.append(hl_diff.shift(lag).rename(f'hl_diff_lag_{lag}'))\n",
    "\n",
    "    # 一括結合＆欠損削除\n",
    "    feat = pd.concat(log_ret_feats + hl_diff_feats, axis=1)\n",
    "    feat.dropna(inplace=True)\n",
    "    return feat\n",
    "\n",
    "# 特徴量作成\n",
    "# feat_train = make_ts_features_norm(df_train, WINDOW)\n",
    "feat_train = make_ts_features_norm(df_train_filtered, WINDOW)\n",
    "feat_valid = make_ts_features_norm(df_valid, WINDOW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea940b",
   "metadata": {},
   "source": [
    "ステップ5：特徴量・ラベルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8234d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_features_and_labels(feat_df, close_series, k):\n",
    "    \"\"\"\n",
    "    feat_df と close_series からラベルを生成し、\n",
    "    両者の共通インデックスのみ抽出して返す\n",
    "    \"\"\"\n",
    "    labels = make_labels(close_series, k)\n",
    "    common = feat_df.index.intersection(labels.index)\n",
    "    return feat_df.loc[common], labels.loc[common]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12288716",
   "metadata": {},
   "source": [
    "ステップ6：データ準備・分割関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# 学習データ\n",
    "X_tr, y_tr = align_features_and_labels(feat_train, df_train['close'], k)\n",
    "# 検証＋テスト用データ\n",
    "X_vf, y_vf = align_features_and_labels(feat_valid, df_valid['close'], k)\n",
    "# valid を検証用/テスト用に 5:5 分割（分布均等・再現性確保）\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_vf, y_vf, test_size=0.5, random_state=SEED, stratify=y_vf\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d836a",
   "metadata": {},
   "source": [
    "ステップ7：モデル学習・評価ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b9fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train k=5:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unknown type of parameter:class_weight, got:dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# (1) モデル学習\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_cb, train_pbar \u001b[38;5;241m=\u001b[39m make_progress_callback(PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     24\u001b[0m     PARAMS,\n\u001b[1;32m     25\u001b[0m     lgb\u001b[38;5;241m.\u001b[39mDataset(X_tr, label\u001b[38;5;241m=\u001b[39my_tr),\n\u001b[1;32m     26\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     27\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mDataset(X_val, label\u001b[38;5;241m=\u001b[39my_val)],\n\u001b[1;32m     28\u001b[0m     feval\u001b[38;5;241m=\u001b[39mprecision_eval,\n\u001b[1;32m     29\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     30\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     31\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     32\u001b[0m         train_cb\n\u001b[1;32m     33\u001b[0m     ]\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m train_pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# (2) テスト進捗バー + 予測\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:297\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    299\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3656\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3650\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3651\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3652\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3653\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3654\u001b[0m     )\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3656\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:2590\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2585\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2586\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2587\u001b[0m             )\n\u001b[1;32m   2588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\n\u001b[1;32m   2591\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   2592\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[1;32m   2593\u001b[0m         reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2594\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   2595\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[1;32m   2596\u001b[0m         init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score,\n\u001b[1;32m   2597\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[1;32m   2598\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[1;32m   2599\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[1;32m   2600\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m   2601\u001b[0m         position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[1;32m   2602\u001b[0m     )\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:2163\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2160\u001b[0m                 params\u001b[38;5;241m.\u001b[39mpop(cat_alias, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   2161\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_column\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(categorical_indices)\n\u001b[0;32m-> 2163\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;66;03m# process for reference dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:554\u001b[0m, in \u001b[0;36m_param_dict_to_str\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    552\u001b[0m         pairs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown type of parameter:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(val)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pairs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Unknown type of parameter:class_weight, got:dict"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "\n",
    "# カスタム評価関数：macro precision\n",
    "def precision_eval(preds, dataset):\n",
    "    labels = dataset.get_label().astype(int)\n",
    "    preds = preds.reshape(-1, 3)\n",
    "    pred_labels = preds.argmax(axis=1)\n",
    "    p = precision_score(labels, pred_labels, average='macro', zero_division=0)\n",
    "    return 'macro_precision', p, True\n",
    "\n",
    "# 学習進捗バー用コールバック作成\n",
    "def make_progress_callback(total, desc):\n",
    "    pbar = tqdm(total=total, desc=desc, leave=False)\n",
    "    def _callback(env):\n",
    "        pbar.update(1)\n",
    "    return _callback, pbar\n",
    "\n",
    "# (1) モデル学習\n",
    "train_cb, train_pbar = make_progress_callback(PARAMS['n_estimators'], desc=f\"Train k={k}\")\n",
    "model = lgb.train(\n",
    "    PARAMS,\n",
    "    lgb.Dataset(X_tr, label=y_tr),\n",
    "    num_boost_round=PARAMS['n_estimators'],\n",
    "    valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
    "    feval=precision_eval,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20, verbose=False),\n",
    "        lgb.log_evaluation(period=0),\n",
    "        train_cb\n",
    "    ]\n",
    ")\n",
    "train_pbar.close()\n",
    "\n",
    "# (2) テスト進捗バー + 予測\n",
    "test_cb, test_pbar = make_progress_callback(len(X_test), desc=f\"Test Predict k={k}\")\n",
    "y_pred_test = []\n",
    "for prob in model.predict(X_test):\n",
    "    test_pbar.update(1)\n",
    "    y_pred_test.append(np.argmax(prob))\n",
    "test_pbar.close()\n",
    "\n",
    "# (3) 結果表示：混合行列\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2])\n",
    "print(f\"\\n=== k = {k} | Params: {PARAMS} ===\")\n",
    "print(\"Test Confusion Matrix:\\n\", cm_test)\n",
    "\n",
    "# (4) 結果表示：precision, recall, f1-score\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred_test,\n",
    "    labels=[0, 1, 2],\n",
    "    target_names=['Min(0)', 'Max(1)', 'Other(2)'],\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# (5) ファイル保存\n",
    "with open(f\"results/report_k{k}.txt\", \"w\") as f:\n",
    "    f.write(\"Test Confusion Matrix:\\n\")\n",
    "    np.savetxt(f, cm_test, fmt='%d')\n",
    "    f.write(\"\\n\\nClassification Report:\\n\")\n",
    "    f.write(classification_report(\n",
    "        y_test, y_pred_test,\n",
    "        labels=[0, 1, 2],\n",
    "        target_names=['Min(0)', 'Max(1)', 'Other(2)'],\n",
    "        digits=4,\n",
    "        zero_division=0\n",
    "    ))\n",
    "print(f\"Saved → results/report_k{k}.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37425474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "\n",
    "# ハイパーパラメータ（1パターン、class_weightは除く）\n",
    "PARAMS = {\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1,\n",
    "    'seed': SEED\n",
    "}\n",
    "\n",
    "# クラスごとの重み（0: Minima, 1: Maxima, 2: Other）\n",
    "class_weights = {0: 10.0, 1: 10.0, 2: 1.0}\n",
    "sample_weights = y_tr.map(class_weights)\n",
    "\n",
    "# LightGBMデータセット（重み付き）\n",
    "train_set = lgb.Dataset(X_tr, label=y_tr, weight=sample_weights)\n",
    "valid_set = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "# カスタム評価関数：macro precision\n",
    "def precision_eval(preds, dataset):\n",
    "    labels = dataset.get_label().astype(int)\n",
    "    preds = preds.reshape(-1, 3)\n",
    "    pred_labels = preds.argmax(axis=1)\n",
    "    p = precision_score(labels, pred_labels, average='macro', zero_division=0)\n",
    "    return 'macro_precision', p, True\n",
    "\n",
    "# 学習進捗バー用コールバック\n",
    "def make_progress_callback(total, desc):\n",
    "    pbar = tqdm(total=total, desc=desc, leave=False)\n",
    "    def _callback(env):\n",
    "        pbar.update(1)\n",
    "    return _callback, pbar\n",
    "\n",
    "# (1) モデル学習\n",
    "train_cb, train_pbar = make_progress_callback(PARAMS['n_estimators'], desc=f\"Train k={k}\")\n",
    "model = lgb.train(\n",
    "    PARAMS,\n",
    "    train_set,\n",
    "    num_boost_round=PARAMS['n_estimators'],\n",
    "    valid_sets=[valid_set],\n",
    "    feval=precision_eval,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20, verbose=False),\n",
    "        lgb.log_evaluation(period=0),\n",
    "        train_cb\n",
    "    ]\n",
    ")\n",
    "train_pbar.close()\n",
    "\n",
    "# (2) テスト予測（進捗バー付き）\n",
    "test_cb, test_pbar = make_progress_callback(len(X_test), desc=f\"Test Predict k={k}\")\n",
    "y_pred_test = []\n",
    "for prob in model.predict(X_test):\n",
    "    test_pbar.update(1)\n",
    "    y_pred_test.append(np.argmax(prob))\n",
    "test_pbar.close()\n",
    "\n",
    "# (3) 混合行列とレポート出力\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2])\n",
    "print(f\"\\n=== k = {k} | Params: {PARAMS} ===\")\n",
    "print(\"Test Confusion Matrix:\\n\", cm_test)\n",
    "\n",
    "report = classification_report(\n",
    "    y_test, y_pred_test,\n",
    "    labels=[0, 1, 2],\n",
    "    target_names=['Min(0)', 'Max(1)', 'Other(2)'],\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    ")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# (4) 保存\n",
    "with open(f\"results/report_k{k}.txt\", \"w\") as f:\n",
    "    f.write(\"Test Confusion Matrix:\\n\")\n",
    "    np.savetxt(f, cm_test, fmt='%d')\n",
    "    f.write(\"\\n\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"Saved → results/report_k{k}.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
